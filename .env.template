# ============================================================================
# Magentic-UI DGX Spark Stack - Environment Configuration
# ============================================================================
# Copy this file to .env and configure your settings:
#   cp .env.template .env
#
# Target: NVIDIA DGX Spark (Blackwell GB10, 128GB Unified Memory)
# ============================================================================

# ----------------------------------------------------------------------------
# HuggingFace Configuration (REQUIRED)
# ----------------------------------------------------------------------------
# Get your token from: https://huggingface.co/settings/tokens
# Ensure you have access to microsoft/Fara-7B
HUGGINGFACE_TOKEN=your_token_here

# ----------------------------------------------------------------------------
# vLLM Inference Server Configuration
# ----------------------------------------------------------------------------
VLLM_HOST=localhost
VLLM_PORT=5000
VLLM_MODEL=microsoft/Fara-7B

# Precision options:
#   auto    - Automatically select (FP16 on Blackwell) - RECOMMENDED
#   float16 - Force FP16
#   float8  - FP8 quantization (smaller, slight accuracy loss)
VLLM_DTYPE=auto

# Maximum context length (Fara-7B supports up to 16384)
VLLM_MAX_MODEL_LEN=16384

# GPU memory utilization (0.0 - 1.0)
# DGX Spark's 128GB allows higher values
VLLM_GPU_MEMORY_UTILIZATION=0.85

# vLLM container image
VLLM_IMAGE=nvcr.io/nvidia/vllm:25.09-py3

# ----------------------------------------------------------------------------
# Magentic-UI Configuration
# ----------------------------------------------------------------------------
MAGENTIC_UI_PORT=4200
MAGENTIC_UI_LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# GPU Settings
# ----------------------------------------------------------------------------
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all

# ----------------------------------------------------------------------------
# Fine-Tuning Configuration (Optional)
# ----------------------------------------------------------------------------
# Weights & Biases for experiment tracking
WANDB_API_KEY=
WANDB_PROJECT=fara-7b-finetune
